# agents/agent6_final_generator.py - Final Generator Agent

import asyncio
from .utils import (
    classify_final_decision,
    analyze_result_quality,
    generate_feedback_suggestion,
    wait_for_feedback
)


async def run_final_generator(job_id: int, job: dict, ws, hitl_stages: list, hitl_retry_counts: dict,
                               objective_review: str, data_analysis: str, risk_analysis: str, roi_estimation: str,
                               bp_cases: list, call_ollama, call_llm, get_job, update_job_status, reset_feedback_state,
                               send_final_report: bool = True, ws_key: str = None, active_connections: dict = None,
                               user_feedbacks: dict = None):
    """Final Generator - Synthesize all analyses into final recommendation

    Args:
        job_id: Job ID
        job: Job data dictionary
        ws: WebSocket connection
        hitl_stages: HITL stage configuration
        hitl_retry_counts: HITL retry counter dictionary
        objective_review: Result from Agent 2
        data_analysis: Result from Agent 3
        risk_analysis: Result from Agent 4
        roi_estimation: Result from Agent 5
        bp_cases: Result from Agent 1
        call_ollama: LLM call function (ollama)
        call_llm: LLM call function (unified)
        get_job: Database get_job function
        update_job_status: Database update_job_status function
        reset_feedback_state: Database reset_feedback_state function
        send_final_report: Whether to send final report to WebSocket
        ws_key: WebSocket key for active connections
        active_connections: Active WebSocket connections dictionary
        user_feedbacks: Dictionary of user feedbacks from agents 2-5

    Returns:
        None (updates job with final report and decision)
    """
    MAX_HITL_RETRIES = 3

    if ws:
        await ws.send_json({"status": "processing", "agent": "Final_Generator", "message": "ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì¤‘..."})

    proposal_text = job.get("content", "")
    enable_seq_thinking = job.get("enable_sequential_thinking", False)

    if enable_seq_thinking:
        print(f"[Agent 6] Sequential Thinking í™œì„±í™”ë¨")

    # Agent 2~5ì˜ ì‚¬ìš©ì í”¼ë“œë°±ì„ ìˆ˜ì§‘í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
    user_feedback_section = ""
    if user_feedbacks:
        feedback_list = []
        agent_names = {2: "ëª©í‘œ ê²€í† ", 3: "ë°ì´í„° ë¶„ì„", 4: "ë¦¬ìŠ¤í¬ ë¶„ì„", 5: "ROI ì¶”ì •"}
        for agent_num, feedback in user_feedbacks.items():
            if feedback:
                agent_name = agent_names.get(agent_num, f"Agent {agent_num}")
                feedback_list.append(f"- {agent_name}: {feedback}")

        if feedback_list:
            user_feedback_section = f"""

**ì‚¬ìš©ìê°€ ì œê³µí•œ ì¤‘ìš” ì •ë³´ (í•„ìˆ˜ ë°˜ì˜):**
{''.join([f + chr(10) for f in feedback_list])}

**ì¤‘ìš”:** ìœ„ ì‚¬ìš©ì í”¼ë“œë°±ì˜ ëª¨ë“  ë‚´ìš©ì„ ìµœì¢… ì˜ê²¬ì— **êµ¬ì²´ì ìœ¼ë¡œ ë°˜ì˜**í•´ì£¼ì„¸ìš”.
íŠ¹íˆ ì˜ˆì‚°, ì¸ë ¥, ê¸°ê°„, ê¸°ìˆ  ì—­ëŸ‰ ë“± êµ¬ì²´ì ì¸ ì •ë³´ê°€ ìˆë‹¤ë©´ ìµœì¢… ì˜ê²¬ì— ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•´ì£¼ì„¸ìš”."""

    final_prompt = f"""ë‹¹ì‹ ì€ AI í”„ë¡œì íŠ¸ ê²€í†  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì œì•ˆì„œì™€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì˜ê²¬ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

ì œì•ˆì„œ ë‚´ìš©:
{proposal_text}

ëª©í‘œ ê²€í† :
{objective_review}

ë°ì´í„° ë¶„ì„:
{data_analysis}

ë¦¬ìŠ¤í¬ ë¶„ì„:
{risk_analysis}

ROI ì¶”ì •:
{roi_estimation}{user_feedback_section}

ë‹¤ìŒì„ í¬í•¨í•œ ìµœì¢… ì˜ê²¬ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. ìŠ¹ì¸ ë˜ëŠ” ë³´ë¥˜ ê¶Œì¥ (ëª…í™•í•˜ê²Œ)
2. ì£¼ìš” ê·¼ê±° (3-4ê°€ì§€)
3. ê¶Œì¥ì‚¬í•­ (2-3ê°€ì§€)

ê°„ê²°í•˜ê²Œ 5-7ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    final_recommendation = await asyncio.to_thread(call_ollama, final_prompt, enable_sequential_thinking=enable_seq_thinking)

    if ws:
        await ws.send_json({"status": "completed", "agent": "Final_Generator", "message": "ìµœì¢… ì˜ê²¬ ìƒì„± ì™„ë£Œ"})
    update_job_status(job_id, "final_done")

    # HITL ì¸í„°ëŸ½íŠ¸: Agent 6 ì´í›„ (ì„¤ì •ì— ë”°ë¼)
    if 6 in hitl_stages:
        agent_num = 6
        skip_accepted_agent6 = False
        while True:
            quality_check = await asyncio.to_thread(
                analyze_result_quality,
                "Final Generator",
                final_recommendation,
                proposal_text,
                call_ollama
            )
            print(f"[DEBUG] Quality check for Agent 6: {quality_check}")

            feedback_suggestion = await asyncio.to_thread(
                generate_feedback_suggestion,
                "Final Generator",
                final_recommendation,
                proposal_text,
                call_ollama
            )

            if ws:
                await ws.send_json({
                    "status": "interrupt",
                    "job_id": job_id,
                    "message": f"ìµœì¢… ì˜ê²¬ í™•ì¸ ì¤‘... (ì¬ì‹œë„ {hitl_retry_counts[agent_num]}/{MAX_HITL_RETRIES}) - {quality_check.get('reason', '')}",
                    "results": {
                        "final_recommendation": final_recommendation,
                        "feedback_suggestion": feedback_suggestion,
                        "quality_check": quality_check
                    }
                })

            # ì‚¬ìš©ìê°€ ê²°ê³¼ë¥¼ í™•ì¸í•  ë•Œê¹Œì§€ ëŒ€ê¸°
            await wait_for_feedback(job_id, update_job_status, get_job)

            updated_job = get_job(job_id)
            skip_requested = updated_job.get("feedback_skip", False)
            user_feedback = (updated_job.get("feedback") or "").strip()

            print(f"[DEBUG] User feedback retrieved (Agent 6): '{user_feedback}' (skip={skip_requested})")

            if skip_requested:
                skip_accepted_agent6 = True
                retry_decision = {"needs_retry": False, "reason": "ì‚¬ìš©ìê°€ ê±´ë„ˆë›°ê¸°ë¥¼ ì„ íƒ"}
                reset_feedback_state(job_id)
                print(f"[DEBUG] HITL skip acknowledged for Agent 6 (job {job_id})")
            elif user_feedback:
                # ì‚¬ìš©ì í”¼ë“œë°±ì´ ìˆìœ¼ë©´ ì¬ë¶„ì„ í•„ìš”
                retry_decision = {"needs_retry": True, "reason": "ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜", "user_feedback": user_feedback}
                # ì‚¬ìš©ì í”¼ë“œë°±ì„ DBì— ì €ì¥ (Agent 7ì—ì„œ ì‚¬ìš©)
                job_data = get_job(job_id)
                if job_data:
                    metadata = job_data.get("metadata", {}).copy()
                    user_feedbacks_dict = metadata.get("user_feedbacks", {})
                    user_feedbacks_dict[agent_num] = user_feedback
                    metadata["user_feedbacks"] = user_feedbacks_dict
                    update_job_status(job_id, job_data.get("status"), metadata=metadata)
                reset_feedback_state(job_id)
            else:
                retry_decision = quality_check

            print(f"[DEBUG] Retry decision for Agent 6: {retry_decision}")

            if skip_accepted_agent6:
                break

            if retry_decision.get("needs_retry") and hitl_retry_counts[agent_num] < MAX_HITL_RETRIES:
                hitl_retry_counts[agent_num] += 1
                print(f"[DEBUG] Agent 6 ì¬ì‹œë„ {hitl_retry_counts[agent_num]}/{MAX_HITL_RETRIES}")

                if ws:
                    await ws.send_json({
                        "status": "processing",
                        "agent": "Final_Generator",
                        "message": f"í’ˆì§ˆ ê°œì„ ì„ ìœ„í•´ ì¬ê²€í†  ì¤‘... ({hitl_retry_counts[agent_num]}/{MAX_HITL_RETRIES})"
                    })

                # ì‚¬ìš©ì í”¼ë“œë°±ì´ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ì „íˆ ë‹¤ë¥´ê²Œ êµ¬ì„±
                if retry_decision.get("user_feedback"):
                    retry_prompt = f"""ë‹¹ì‹ ì€ AI í”„ë¡œì íŠ¸ ê²€í†  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì¤‘ìš”í•œ í”¼ë“œë°±ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤. ì´ í”¼ë“œë°±ì„ **ë°˜ë“œì‹œ ë°˜ì˜**í•˜ì—¬ ìµœì¢… ì˜ê²¬ì„ ë‹¤ì‹œ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì œì•ˆì„œ ë‚´ìš©:
{proposal_text}

ëª©í‘œ ê²€í† :
{objective_review}

ë°ì´í„° ë¶„ì„:
{data_analysis}

ë¦¬ìŠ¤í¬ ë¶„ì„:
{risk_analysis}

ROI ì¶”ì •:
{roi_estimation}

ì´ì „ ìµœì¢… ì˜ê²¬:
{final_recommendation}

**ì‚¬ìš©ì í”¼ë“œë°± (í•„ìˆ˜ ë°˜ì˜):**
{retry_decision.get('user_feedback')}

**ì¤‘ìš”:** ìœ„ ì‚¬ìš©ì í”¼ë“œë°±ì˜ ë‚´ìš©ì„ ìµœì¢… ì˜ê²¬ì— **êµ¬ì²´ì ìœ¼ë¡œ ë°˜ì˜**í•´ì£¼ì„¸ìš”.
ì‚¬ìš©ìê°€ ì œê³µí•œ ëª¨ë“  ì •ë³´(ì˜ˆ: ì˜ˆì‚°, ì¸ë ¥, ê¸°ê°„, ê¸°ìˆ  ì—­ëŸ‰ ë“±)ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•˜ê³ ,
ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ í¬í•¨í•œ ìµœì¢… ì˜ê²¬ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. ìŠ¹ì¸/ë³´ë¥˜ ê¶Œì¥ (ì‚¬ìš©ì í”¼ë“œë°±ì„ ê³ ë ¤í•œ ëª…í™•í•œ ê²°ì •)
2. ì£¼ìš” ê·¼ê±° (ì‚¬ìš©ì í”¼ë“œë°±ì˜ ì •ë³´ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©í•˜ì—¬ 3-4ê°€ì§€)
3. ì‹¤í–‰ ê¶Œì¥ì‚¬í•­ (ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ë¥¼ ë°˜ì˜í•œ êµ¬ì²´ì ì¸ ì œì•ˆ 2-3ê°€ì§€)

**ë°˜ë“œì‹œ ì‚¬ìš©ì í”¼ë“œë°±ì˜ ë‚´ìš©ì„ ìµœì¢… ì˜ê²¬ì— ì§ì ‘ ì–¸ê¸‰í•˜ë©´ì„œ 7-10ë¬¸ì¥ ì´ìƒìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.**
ì˜ˆ: "ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ì˜ˆì‚° 3ì–µì›ì„ ê³ ë ¤í•  ë•Œ..." ë˜ëŠ” "ì œê³µëœ ì¸ë ¥ ì •ë³´ì— ë”°ë¥´ë©´..." ë“±"""
                else:
                    retry_prompt = f"""ë‹¹ì‹ ì€ AI í”„ë¡œì íŠ¸ ê²€í†  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì´ì „ ìµœì¢… ì˜ê²¬ì´ í’ˆì§ˆ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” ìƒì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ìµœì¢… ì˜ê²¬ì„ ì¬ì‘ì„±í•´ì£¼ì„¸ìš”.

ì œì•ˆì„œ ë‚´ìš©:
{proposal_text}

ëª©í‘œ ê²€í† :
{objective_review}

ë°ì´í„° ë¶„ì„:
{data_analysis}

ë¦¬ìŠ¤í¬ ë¶„ì„:
{risk_analysis}

ROI ì¶”ì •:
{roi_estimation}

ì´ì „ ìµœì¢… ì˜ê²¬ (ë¶ˆì¶©ë¶„):
{final_recommendation}

í’ˆì§ˆ ê²€ì‚¬ ê²°ê³¼:
- ë¬¸ì œì : {retry_decision.get('reason', 'ì˜ê²¬ì´ ë¶ˆì¶©ë¶„í•¨')}
- ë³´ì™„ í•„ìš” ì‚¬í•­: {', '.join(retry_decision.get('additional_info_needed', ['ë” ëª…í™•í•œ íŒë‹¨', 'êµ¬ì²´ì ì¸ ê·¼ê±°']))}

ìœ„ ë¬¸ì œì ì„ í•´ê²°í•˜ê³  ë‹¤ìŒì„ í¬í•¨í•œ **êµ¬ì²´ì ì´ê³  ëª…í™•í•œ** ìµœì¢… ì˜ê²¬ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. ìŠ¹ì¸/ë³´ë¥˜ ê¶Œì¥ (ëª…í™•í•œ ê²°ì •ê³¼ ì´ìœ )
2. ì£¼ìš” ê·¼ê±° (êµ¬ì²´ì ì¸ ë°ì´í„°ì™€ ë¶„ì„ ê²°ê³¼ ì¸ìš©)
3. ì‹¤í–‰ ê¶Œì¥ì‚¬í•­ (êµ¬ì²´ì ì´ê³  ì‹¤í˜„ ê°€ëŠ¥í•œ ì œì•ˆ)

**ë°˜ë“œì‹œ 7-10ë¬¸ì¥ ì´ìƒìœ¼ë¡œ ëª…í™•í•œ íŒë‹¨ê³¼ ìƒì„¸í•œ ê·¼ê±°ë¥¼ í¬í•¨í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”.**"""

                final_recommendation = await asyncio.to_thread(call_ollama, retry_prompt, enable_sequential_thinking=enable_seq_thinking)

                if ws:
                    await ws.send_json({
                        "status": "completed",
                        "agent": "Final_Generator",
                        "message": "ì¬ê²€í†  ì™„ë£Œ"
                    })

                continue
            else:
                if hitl_retry_counts[agent_num] >= MAX_HITL_RETRIES:
                    print(f"[DEBUG] Agent 6 ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ë„ë‹¬")
                    if ws:
                        await ws.send_json({
                            "status": "processing",
                            "agent": "Final_Generator",
                            "message": "ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ë„ë‹¬, ìµœì¢… ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤"
                        })
                break

        if ws:
            next_message = (
                "ì‚¬ìš©ì ê±´ë„ˆë›°ê¸° ìš”ì²­ì„ ìˆ˜ë½í–ˆìŠµë‹ˆë‹¤. ìµœì¢… ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
                if skip_accepted_agent6
                else "í”¼ë“œë°± ë°˜ì˜í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì¤‘..."
            )
            await ws.send_json({"status": "processing", "message": next_message})
        await asyncio.sleep(1)

    # ìµœì¢… ì™„ë£Œ
    final_report = f"""
    <div style="padding: 20px;">
        <h2>ğŸ“Š AI ê³¼ì œ ì§€ì›ì„œ ê²€í†  ë³´ê³ ì„œ</h2>
        <hr/>

        <div class="accordion-item">
            <div class="accordion-header" onclick="toggleAccordion('section1')">
                <span>1. BP ì‚¬ë¡€ ë¶„ì„ ({len(bp_cases)}ê±´)</span>
                <span class="accordion-icon">â–¼</span>
            </div>
            <div id="section1" class="accordion-content">
                <p><strong>ìœ ì‚¬ ì‚¬ë¡€:</strong></p>
                {''.join([f'''
                <div style="background: #f8f9fa; padding: 12px; margin: 10px 0; border-left: 3px solid #007bff; border-radius: 4px;">
                    <h4 style="margin: 0 0 8px 0; color: #007bff;">{idx+1}. {f'<a href="{c.get("link")}" target="_blank" style="color: #007bff; text-decoration: none;">{c.get("title", "ì œëª© ì—†ìŒ")} ğŸ”—</a>' if c.get("link") else c.get("title", "ì œëª© ì—†ìŒ")}</h4>
                    <p style="margin: 4px 0;"><strong>ê¸°ìˆ  ìœ í˜•:</strong> {c.get("tech_type", "N/A")}</p>
                    <p style="margin: 4px 0;"><strong>ë„ë©”ì¸:</strong> {c.get("business_domain", c.get("domain", "N/A"))} | <strong>ì‚¬ì—…ë¶€:</strong> {c.get("division", "N/A")}</p>
                    <p style="margin: 4px 0;"><strong>ë¬¸ì œ (AS-IS):</strong> {c.get("problem_as_was", "N/A")}</p>
                    <p style="margin: 4px 0;"><strong>ì†”ë£¨ì…˜ (TO-BE):</strong> {c.get("solution_to_be", "N/A")}</p>
                    <p style="margin: 4px 0; background: #fff3cd; padding: 8px; border-radius: 3px;"><strong>ğŸ’ í•µì‹¬ ìš”ì•½:</strong> {c.get("summary", "N/A")}</p>
                    {f'<p style="margin: 4px 0; background: #d1ecf1; padding: 8px; border-radius: 3px;"><strong>ğŸ’¡ íŒ:</strong> {c.get("tips")}</p>' if c.get("tips") else ''}
                    {f'<p style="margin: 8px 0 0 0;"><a href="{c.get("link")}" target="_blank" style="color: #007bff; text-decoration: none; font-size: 0.9em;">ğŸ“„ ì›ë³¸ ë¬¸ì„œ ë³´ê¸° â†’</a></p>' if c.get("link") else ''}
                </div>
                ''' for idx, c in enumerate(bp_cases)]) if bp_cases else '<p>ê²€ìƒ‰ëœ ì‚¬ë¡€ ì—†ìŒ</p>'}
                <p style="margin-top: 15px;"><em>ì´ {len(bp_cases)}ê±´ì˜ ìœ ì‚¬ ì‚¬ë¡€ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.</em></p>
            </div>
        </div>

        <div class="accordion-item">
            <div class="accordion-header" onclick="toggleAccordion('section2')">
                <span>2. ëª©í‘œ ì í•©ì„±</span>
                <span class="accordion-icon">â–¼</span>
            </div>
            <div id="section2" class="accordion-content">
                <div class="markdown-content" data-markdown>{objective_review}</div>
            </div>
        </div>

        <div class="accordion-item">
            <div class="accordion-header" onclick="toggleAccordion('section3')">
                <span>3. ë°ì´í„° ë¶„ì„</span>
                <span class="accordion-icon">â–¼</span>
            </div>
            <div id="section3" class="accordion-content">
                <div class="markdown-content" data-markdown>{data_analysis}</div>
            </div>
        </div>

        <div class="accordion-item">
            <div class="accordion-header" onclick="toggleAccordion('section4')">
                <span>4. ë¦¬ìŠ¤í¬ ë¶„ì„</span>
                <span class="accordion-icon">â–¼</span>
            </div>
            <div id="section4" class="accordion-content">
                <div class="markdown-content" data-markdown>{risk_analysis}</div>
            </div>
        </div>

        <div class="accordion-item">
            <div class="accordion-header" onclick="toggleAccordion('section5')">
                <span>5. ROI ì¶”ì •</span>
                <span class="accordion-icon">â–¼</span>
            </div>
            <div id="section5" class="accordion-content">
                <div class="markdown-content" data-markdown>{roi_estimation}</div>
            </div>
        </div>

        <div class="accordion-item">
            <div class="accordion-header" onclick="toggleAccordion('section6')">
                <span>6. ìµœì¢… ì˜ê²¬</span>
                <span class="accordion-icon">â–¼</span>
            </div>
            <div id="section6" class="accordion-content" style="display: block;">
                <div class="markdown-content" data-markdown>{final_recommendation}</div>
                <div style="margin-top: 15px; text-align: right;">
                    <button onclick="window.location.href='/api/export/final-recommendation/{job_id}'"
                            style="background-color: #007bff; color: white; border: none; padding: 10px 20px; border-radius: 5px; cursor: pointer; font-size: 14px;">
                        ğŸ“„ ìµœì¢… ì˜ê²¬ PDF ë‹¤ìš´ë¡œë“œ
                    </button>
                </div>
            </div>
        </div>
    </div>
    """

    decision_result = await classify_final_decision(final_report, final_recommendation, call_llm)
    decision_value = decision_result.get("decision", "ë³´ë¥˜")
    decision_reason = decision_result.get("reason", "LLM íŒë‹¨ì„ ê¸°ì¤€ìœ¼ë¡œ ìë™ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

    latest_job = get_job(job_id) or {}
    metadata = latest_job.get("metadata", {}).copy()
    metadata["report"] = final_report
    agent_results = metadata.setdefault("agent_results", {})
    agent_results["final_recommendation"] = final_recommendation
    metadata["final_decision"] = {
        "decision": decision_value,
        "reason": decision_reason,
    }

    update_job_status(
        job_id,
        "completed",
        metadata=metadata,
        llm_decision=decision_value,
    )

    if send_final_report:
        target_ws = ws or (active_connections.get(ws_key) if active_connections and ws_key else None)
        if target_ws:
            human_decision_value = latest_job.get("decision") or latest_job.get("human_decision")
            await target_ws.send_json({
                "status": "completed",
                "agent": "Final_Generator",
                "message": "ê²€í†  ì™„ë£Œ",
                "report": final_report,
                "decision": decision_value,
                "decision_reason": decision_reason,
                "human_decision": human_decision_value,
            })
